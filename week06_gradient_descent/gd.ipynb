{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the sigmoid function for activations \n",
    "# 定义 sigmoid 激活函数\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Derivative of the sigmoid function\n",
    "# 激活函数的导数\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Input data\n",
    "# 输入数据\n",
    "x = np.array([0.1, 0.3])\n",
    "# Target\n",
    "# 目标\n",
    "y = 0.2\n",
    "# Input to output weights\n",
    "# 输入到输出的权重\n",
    "weights = np.array([-0.8, 0.5])\n",
    "\n",
    "# The learning rate, eta in the weight step equation\n",
    "# 权重更新的学习率\n",
    "learnrate = 0.5\n",
    "\n",
    "# the linear combination performed by the node (h in f(h) and f'(h))\n",
    "# 输入和权重的线性组合\n",
    "h = x[0]*weights[0] + x[1]*weights[1]\n",
    "# or h = np.dot(x, weights)\n",
    "\n",
    "# The neural network output (y-hat)\n",
    "# 神经网络输出\n",
    "nn_output = sigmoid(h)\n",
    "\n",
    "# output error (y - y-hat)\n",
    "# 输出误差\n",
    "error = y - nn_output\n",
    "\n",
    "# output gradient (f'(h))\n",
    "# 输出梯度\n",
    "output_grad = sigmoid_prime(h)\n",
    "\n",
    "# error term (lowercase delta)\n",
    "error_term = error * output_grad\n",
    "\n",
    "# Gradient descent step \n",
    "# 梯度下降一步\n",
    "del_w = [ learnrate * error_term * x[0],\n",
    "          learnrate * error_term * x[1]]\n",
    "# or del_w = learnrate * error_term * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network output:\n",
      "0.6899744811276125\n",
      "Amount of Error:\n",
      "-0.1899744811276125\n",
      "Change in Weights:\n",
      "[-0.02031869 -0.04063738 -0.06095608 -0.08127477]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    \"\"\"\n",
    "    # Derivative of the sigmoid function\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "learnrate = 0.5\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array(0.5)\n",
    "\n",
    "# Initial weights\n",
    "w = np.array([0.5, -0.5, 0.3, 0.1])\n",
    "\n",
    "### Calculate one gradient descent step for each weight\n",
    "### Note: Some steps have been consolidated, so there are fewer variable names than in the above sample code\n",
    "\n",
    "# TODO: Calculate the node's linear combination of inputs and weights\n",
    "h = np.dot(x, w)\n",
    "\n",
    "# TODO: Calculate output of neural network\n",
    "nn_output = sigmoid(h)\n",
    "\n",
    "# TODO: Calculate error of neural network\n",
    "error = y-nn_output\n",
    "\n",
    "# TODO: Calculate the error term\n",
    "#       Remember, this requires the output gradient, which we haven't specifically added a variable for.\n",
    "error_term = error*sigmoid_prime(h)\n",
    "\n",
    "# TODO: Calculate change in weights\n",
    "del_w = learnrate*error_term*x\n",
    "\n",
    "print('Neural Network output:')\n",
    "print(nn_output)\n",
    "print('Amount of Error:')\n",
    "print(error)\n",
    "print('Change in Weights:')\n",
    "print(del_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "admissions = pd.read_csv('binary.csv')\n",
    "\n",
    "# Make dummy variables for rank\n",
    "data = pd.concat([admissions, pd.get_dummies(admissions['rank'], prefix='rank')], axis=1)\n",
    "data = data.drop('rank', axis=1)\n",
    "\n",
    "# Standarize features\n",
    "for field in ['gre', 'gpa']:\n",
    "    mean, std = data[field].mean(), data[field].std()\n",
    "    data.loc[:,field] = (data[field]-mean)/std\n",
    "    \n",
    "# Split off random 10% of the data for testing\n",
    "np.random.seed(42)\n",
    "sample = np.random.choice(data.index, size=int(len(data)*0.9), replace=False)\n",
    "data, test_data = data.iloc[sample], data.drop(sample)\n",
    "\n",
    "# Split into features and targets\n",
    "features, targets = data.drop('admit', axis=1), data['admit']\n",
    "features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用梯度下降来更新权重的算法概述：\n",
    "\n",
    "权重步长设定为 0： \\Delta w_i = 0Δw \n",
    "i\n",
    "​\t =0\n",
    "对训练数据中的每一条记录：\n",
    "通过网络做正向传播，计算输出 \\hat y = f(\\sum_i w_i x_i) \n",
    "y\n",
    "^\n",
    "​\t =f(∑ \n",
    "i\n",
    "​\t w \n",
    "i\n",
    "​\t x \n",
    "i\n",
    "​\t )\n",
    "计算输出单元的误差项（error term） \\delta = (y - \\hat y) * f'(\\sum_i w_i x_i)δ=(y− \n",
    "y\n",
    "^\n",
    "​\t )∗f \n",
    "′\n",
    " (∑ \n",
    "i\n",
    "​\t w \n",
    "i\n",
    "​\t x \n",
    "i\n",
    "​\t )\n",
    "更新权重步长 \\Delta w_i = \\Delta w_i + \\delta x_iΔw \n",
    "i\n",
    "​\t =Δw \n",
    "i\n",
    "​\t +δx \n",
    "i\n",
    "​\t \n",
    "更新权重 w_i = w_i + \\eta \\Delta w_i / mw \n",
    "i\n",
    "​\t =w \n",
    "i\n",
    "​\t +ηΔw \n",
    "i\n",
    "​\t /m。其中 \\etaη 是学习率， mm 是数据点个数。这里我们对权重步长做了平均，为的是降低训练数据中大的变化。\n",
    "重复 ee 代（epoch）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.26276093849966364\n",
      "Train loss:  0.20928619409324895\n",
      "Train loss:  0.20084292908073417\n",
      "Train loss:  0.1986215647552789\n",
      "Train loss:  0.19779851396686018\n",
      "Train loss:  0.19742577912189863\n",
      "Train loss:  0.19723507746241065\n",
      "Train loss:  0.19712945625092465\n",
      "Train loss:  0.19706766341315074\n",
      "Train loss:  0.19703005801777368\n",
      "Prediction accuracy: 0.725\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# TODO: We haven't provided the sigmoid_prime function like we did in\n",
    "#       the previous lesson to encourage you to come up with a more\n",
    "#       efficient solution. If you need a hint, check out the comments\n",
    "#       in solution.py from the previous lecture.\n",
    "\n",
    "# Use to same seed to make debugging easier\n",
    "np.random.seed(42)\n",
    "\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "\n",
    "# Initialize weights\n",
    "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "\n",
    "# Neural Network hyperparameters\n",
    "epochs = 1000\n",
    "learnrate = 0.5\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w = np.zeros(weights.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        # Loop through all records, x is the input, y is the target\n",
    "\n",
    "        # Note: We haven't included the h variable from the previous\n",
    "        #       lesson. You can add it if you want, or you can calculate\n",
    "        #       the h together with the output\n",
    "\n",
    "        # TODO: Calculate the output---#RIGHT\n",
    "        output = sigmoid(np.dot(x, weights))\n",
    "\n",
    "        # TODO: Calculate the error---#WRONG\n",
    "#         error = np.abs(y-output)\n",
    "        error = y-output\n",
    "\n",
    "        # TODO: Calculate the error term---#RIGHT\n",
    "        error_term = error*output*(1-output)\n",
    "\n",
    "        # TODO: Calculate the change in weights for this sample\n",
    "        #       and add it to the total weight change---#RIGHT\n",
    "        del_w += error_term*x\n",
    "\n",
    "    # TODO: Update weights using the learning rate and the average change in weights\n",
    "    weights += learnrate*del_w/n_records\n",
    "\n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        out = sigmoid(np.dot(features, weights))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "tes_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = tes_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## self MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要实现一个 4x3x2 网络的正向传播，用 sigmoid 作为两层的激活函数。\n",
    "\n",
    "要做的事情：\n",
    "\n",
    "\n",
    "> 1.计算隐藏层的输入       \n",
    "> 2.计算隐藏层输出         \n",
    "> 3.计算输出层的输入       \n",
    "> 4.计算神经网络的输出    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden-layer Output:\n",
      "[0.41492192 0.42604313 0.5002434 ]\n",
      "Output-layer Output:\n",
      "[0.49815196 0.48539772]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Network size\n",
    "N_input = 4\n",
    "N_hidden = 3\n",
    "N_output = 2\n",
    "\n",
    "np.random.seed(42)\n",
    "# Make some fake data\n",
    "X = np.random.randn(4)\n",
    "\n",
    "weights_input_to_hidden = np.random.normal(0, scale=0.1, size=(N_input, N_hidden))\n",
    "weights_hidden_to_output = np.random.normal(0, scale=0.1, size=(N_hidden, N_output))\n",
    "\n",
    "\n",
    "# TODO: Make a forward pass through the network\n",
    "hidden_layer_in = np.dot(X, weights_input_to_hidden)\n",
    "hidden_layer_out = sigmoid(hidden_layer_in)\n",
    "\n",
    "print('Hidden-layer Output:')\n",
    "print(hidden_layer_out)\n",
    "\n",
    "output_layer_in = np.dot(hidden_layer_out, weights_hidden_to_output)\n",
    "output_layer_out = sigmoid(output_layer_in)\n",
    "\n",
    "print('Output-layer Output:')\n",
    "print(output_layer_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,) (3, 2) (2,)\n",
      "**************************************************1\n",
      "(3,)\n",
      "(2,)\n",
      "[0.55971365 0.38698582]\n",
      "**************************************************2\n",
      "-0.06012438223148006\n",
      "0.48497343084992534\n",
      "**************************************************output_et\n",
      "0.028730669543515018 ()\n",
      "**************************************************\n",
      "0.028730669543515018 [ 0.1 -0.3] [0.55971365 0.38698582]\n",
      "() (2,) (2,)\n",
      "**************************************************hidden_et\n",
      "[ 0.00287307 -0.0086192 ] (2,)\n",
      "[0.55971365 0.38698582] [0.44028635 0.61301418]\n",
      "[ 0.00070802 -0.00204471] (2,)\n",
      "(2,) (2,)\n",
      "**************************************************\n",
      "(2,) (3,)\n",
      "[ 0.00070802 -0.00204471] [ 0.5  0.1 -0.2]\n",
      "**************************************************\n",
      "Change in weights for hidden layer to output layer:\n",
      "[0.00804047 0.00555918]\n",
      "Change in weights for input layer to hidden layer:\n",
      "[[ 1.77005547e-04 -5.11178506e-04]\n",
      " [ 3.54011093e-05 -1.02235701e-04]\n",
      " [-7.08022187e-05  2.04471402e-04]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "x = np.array([0.5, 0.1, -0.2])\n",
    "target = 0.6\n",
    "learnrate = 0.5\n",
    "\n",
    "weights_input_hidden = np.array([[0.5, -0.6],\n",
    "                                 [0.1, -0.2],\n",
    "                                 [0.1, 0.7]])\n",
    "\n",
    "weights_hidden_output = np.array([0.1, -0.3])\n",
    "print(x.shape, weights_input_hidden.shape, weights_hidden_output.shape)\n",
    "\n",
    "## Forward pass\n",
    "hidden_layer_input = np.dot(x, weights_input_hidden)\n",
    "print('*'*50+'1')\n",
    "print(x.shape)\n",
    "print(hidden_layer_input.shape)\n",
    "hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "print(hidden_layer_output)\n",
    "\n",
    "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "print('*'*50+'2')\n",
    "print(output_layer_in)\n",
    "output = sigmoid(output_layer_in)\n",
    "print(output)\n",
    "\n",
    "## Backwards pass\n",
    "## TODO: Calculate output error\n",
    "error = target - output\n",
    "\n",
    "# TODO: Calculate error term for output layer\n",
    "print('*'*50+'output_et')\n",
    "output_error_term = error * output * (1-output)\n",
    "print(output_error_term, output_error_term.shape)\n",
    "\n",
    "# TODO: Calculate error term for hidden layer\n",
    "# hidden_error = np.dot(output_error_term, weights_hidden_output)\n",
    "print('*'*50)\n",
    "print(output_error_term, weights_hidden_output, hidden_layer_output)\n",
    "print(output_error_term.shape, weights_hidden_output.shape, hidden_layer_output.shape)\n",
    "hidden_error_term = np.dot(output_error_term, weights_hidden_output) * hidden_layer_output * (1 - hidden_layer_output)\n",
    "print('*'*50+'hidden_et')\n",
    "print(np.dot(output_error_term, weights_hidden_output), np.dot(output_error_term, weights_hidden_output).shape)\n",
    "print(hidden_layer_output, (1 - hidden_layer_output))\n",
    "print(hidden_error_term, hidden_error_term.shape)\n",
    "print(np.dot(output_error_term, weights_hidden_output).shape, hidden_layer_output.shape)\n",
    "\n",
    "# TODO: Calculate change in weights for hidden layer to output layer\n",
    "delta_w_h_o = learnrate * output_error_term * hidden_layer_output\n",
    "\n",
    "# TODO: Calculate change in weights for input layer to hidden layer\n",
    "print('*'*50)\n",
    "print(hidden_error_term.shape, x.shape)\n",
    "print(hidden_error_term, x)\n",
    "delta_w_i_h = learnrate * hidden_error_term * x[:, None]\n",
    "\n",
    "print('*'*50)\n",
    "print('Change in weights for hidden layer to output layer:')\n",
    "print(delta_w_h_o)\n",
    "print('Change in weights for input layer to hidden layer:')\n",
    "print(delta_w_i_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backpropagation II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.2759952337979974\n",
      "Train loss:  0.2536039891630312\n",
      "Train loss:  0.2406311012332461\n",
      "Train loss:  0.23311403345410195\n",
      "Train loss:  0.22865891204402225\n",
      "Train loss:  0.22593795573755224\n",
      "Train loss:  0.22422426346337285\n",
      "Train loss:  0.22311377786966663\n",
      "Train loss:  0.22237609891584925\n",
      "Train loss:  0.22187608079923876\n",
      "Prediction accuracy: 0.750\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(21)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "n_hidden = 2  # number of hidden units\n",
    "epochs = 900\n",
    "# learnrate = 0.005\n",
    "learnrate = 0.1\n",
    "\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "# Initialize weights\n",
    "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                        size=(n_features, n_hidden))\n",
    "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                         size=n_hidden)\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
    "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        ## Forward pass ##\n",
    "        # TODO: Calculate the output\n",
    "        hidden_input = np.dot(x, weights_input_hidden)\n",
    "        hidden_output = sigmoid(hidden_input)\n",
    "\n",
    "        output = np.dot(hidden_output,\n",
    "                                weights_hidden_output))\n",
    "\n",
    "        ## Backward pass ##\n",
    "        # TODO: Calculate the network's prediction error\n",
    "        error = y - output\n",
    "\n",
    "        # TODO: Calculate error term for the output unit\n",
    "        output_error_term = error * output * (1 - output)\n",
    "\n",
    "        ## propagate errors to hidden layer\n",
    "\n",
    "        # TODO: Calculate the hidden layer's contribution to the error\n",
    "        hidden_error = np.dot(output_error_term, weights_hidden_output)\n",
    "\n",
    "        # TODO: Calculate the error term for the hidden layer\n",
    "        hidden_error_term = hidden_error * hidden_output * (1 - hidden_output)\n",
    "\n",
    "        # TODO: Update the change in weights\n",
    "        del_w_hidden_output += output_error_term * hidden_output\n",
    "        del_w_input_hidden += hidden_error_term * x[:, None]\n",
    "\n",
    "    # TODO: Update weights\n",
    "    weights_input_hidden += learnrate * del_w_input_hidden / n_records\n",
    "    weights_hidden_output += learnrate * del_w_hidden_output / n_records\n",
    "\n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        hidden_output = sigmoid(np.dot(x, weights_input_hidden))\n",
    "        out = sigmoid(np.dot(hidden_output,\n",
    "                             weights_hidden_output))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
    "out = sigmoid(np.dot(hidden, weights_hidden_output))\n",
    "predictions = out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test normal datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = np.array([[0.5, -0.2, 0.1]])\n",
    "targets = np.array([[0.4]])\n",
    "learnrate = 0.5\n",
    "\n",
    "# 3*2\n",
    "weights_input_hidden = np.array([[0.1, -0.2],\n",
    "                                 [0.4, 0.5],\n",
    "                                 [-0.3, 0.2]])\n",
    "# 2*1\n",
    "weights_hidden_output = np.array([[0.3],\n",
    "                                  [-0.1]])\n",
    "# x = np.array([0.5, 0.1, -0.2])\n",
    "# target = 0.6\n",
    "# learnrate = 0.5\n",
    "\n",
    "# weights_input_hidden = np.array([[0.5, -0.6],\n",
    "#                                  [0.1, -0.2],\n",
    "#                                  [0.1, 0.7]])\n",
    "\n",
    "# weights_hidden_output = np.array([0.1, -0.3])\n",
    "\n",
    "delta_weights_i_h = np.zeros(weights_input_hidden.shape)\n",
    "delta_weights_h_o = np.zeros(weights_hidden_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3) (1, 1) (3, 2) (2, 1)\n"
     ]
    }
   ],
   "source": [
    "# (3,) float (3, 2) (2,)\n",
    "print(inputs.shape, targets.shape, weights_input_hidden.shape, weights_hidden_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************start\n",
      "[ 0.5 -0.2  0.1] [0.4]\n",
      "**************************************************error\n",
      "[-0.12322849]\n",
      "**************************************************hidden_error\n",
      "[-0.0360372   0.01319681]\n",
      "**************************************************delta\n",
      "Change in weights for hidden layer to output layer:\n",
      "[[-0.03001429]\n",
      " [-0.02817863]]\n",
      "Change in weights for input layer to hidden layer:\n",
      "[[-0.00918281  0.003186  ]\n",
      " [ 0.00367312 -0.0012744 ]\n",
      " [-0.00183656  0.0006372 ]]\n",
      "**************************************************END\n",
      "[[ 0.27743499]\n",
      " [-0.12118151]] (2, 1)\n",
      "[[ 0.09306739 -0.19763219]\n",
      " [ 0.40277304  0.49905288]\n",
      " [-0.30138652  0.20047356]] (3, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "for x, target in zip(inputs, targets):\n",
    "    print('*'*50+'start')\n",
    "    print(x, target)\n",
    "    ## Forward pass\n",
    "    hidden_inputs = np.dot(x, weights_input_hidden) # signals into hidden layer\n",
    "    hidden_outputs = sigmoid(hidden_inputs) # signals from hidden layer\n",
    "\n",
    "    # TODO: Output layer - Replace these values with your calculations.\n",
    "    final_inputs = np.dot(hidden_outputs, weights_hidden_output) # signals into final output layer\n",
    "    final_outputs = sigmoid(final_inputs) # signals from final output layer\n",
    "\n",
    "    #### Implement the backward pass here ####\n",
    "    ### Backward pass ###\n",
    "\n",
    "    # TODO: Output error - Replace this value with your calculations.\n",
    "    error = target - final_outputs # Output layer error is the difference between desired target and actual output.\n",
    "    print('*'*50+'error')\n",
    "    print(error)\n",
    "    \n",
    "    # TODO: Calculate the hidden layer's contribution to the error\n",
    "    hidden_error = np.dot(weights_hidden_output, error)\n",
    "    print('*'*50+'hidden_error')\n",
    "    print(hidden_error)\n",
    "\n",
    "    # TODO: Backpropagated error terms - Replace these values with your calculations.\n",
    "    output_error_term = error * final_outputs * (1-final_outputs)\n",
    "    hidden_error_term = hidden_error * hidden_outputs * (1-hidden_outputs)\n",
    "\n",
    "    # Weight step (input to hidden)\n",
    "    delta_weights_i_h += hidden_error_term * x[:, None]\n",
    "    # Weight step (hidden to output)\n",
    "    delta_weights_h_o += (output_error_term * hidden_outputs)[:, None]\n",
    "    print('*'*50+'delta')\n",
    "    print('Change in weights for hidden layer to output layer:')\n",
    "    print(delta_weights_h_o)\n",
    "    print('Change in weights for input layer to hidden layer:')\n",
    "    print(delta_weights_i_h)\n",
    "weights_hidden_output += learnrate * delta_weights_h_o / 1\n",
    "weights_input_hidden += learnrate * delta_weights_i_h / 1\n",
    "print('*'*50+'END')\n",
    "print(weights_hidden_output, weights_hidden_output.shape)\n",
    "print(weights_input_hidden, weights_input_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19039158]\n",
      " [-0.20307588]] (2, 1)\n",
      "[[ 0.06789587 -0.18699981]\n",
      " [ 0.41284165  0.49479992]\n",
      " [-0.30642083  0.20260004]] (3, 2)\n"
     ]
    }
   ],
   "source": [
    "print(weights_hidden_output, weights_hidden_output.shape)\n",
    "print(weights_input_hidden, weights_input_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(weights_hidden_output, np.array([[ 0.37275328], \n",
    "                                              [-0.03172939]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0.5, -0.2, 0.1]])\n",
    "target = np.array([[0.4]])\n",
    "learnrate = 0.5\n",
    "\n",
    "# 3*2\n",
    "weights_input_hidden = np.array([[0.1, -0.2],\n",
    "                                 [0.4, 0.5],\n",
    "                                 [-0.3, 0.2]])\n",
    "# 2*1\n",
    "weights_hidden_output = np.array([[0.3],\n",
    "                                  [-0.1]])\n",
    "\n",
    "delta_weights_i_h = np.zeros(weights_input_hidden.shape)\n",
    "delta_weights_h_o = np.zeros(weights_hidden_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5 -0.2  0.1]] (1, 3)\n",
      "[[0.4]] (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x, x.shape)\n",
    "print(target, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]] (3, 2)\n",
      "[[0.]\n",
      " [0.]] (2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(delta_weights_i_h, delta_weights_i_h.shape)\n",
    "print(delta_weights_h_o, delta_weights_h_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.1, -0.2],\n",
       "        [ 0.4,  0.5],\n",
       "        [-0.3,  0.2]]), (3, 2))"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_input_hidden, weights_input_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.3],\n",
       "        [-0.1]]), (2, 1))"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_hidden_output, weights_hidden_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.4850045 , 0.45512111]]), (1, 2))"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_output = sigmoid(np.dot(x, weights_input_hidden))\n",
    "\n",
    "hidden_output, hidden_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.3],\n",
       "        [-0.1]]), (2, 1))"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_hidden_output, weights_hidden_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.53225901]), (1,))"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = sigmoid(np.dot(hidden_layer_output, weights_hidden_output))\n",
    "\n",
    "final_output, final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.4]]), array([[-0.08497343]]))"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = target - output\n",
    "\n",
    "target, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.02549203],\n",
       "        [ 0.00849734]]), (2, 1))"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_error = np.dot(weights_hidden_output, error)\n",
    "\n",
    "hidden_error, hidden_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02115493]])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_error_term = error * final_output * (1-final_output)\n",
    "\n",
    "output_error_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.02549203],\n",
       "        [ 0.00849734]]),\n",
       " array([[0.4850045 , 0.45512111]]),\n",
       " array([0.4850045 , 0.45512111]))"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_error, hidden_output, hidden_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1), (1, 2), (2,))"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_error.shape, hidden_output.shape, hidden_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00636728],\n",
       "       [ 0.00210722]])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_error_term = hidden_error * hidden_output[0][:, None] * (1-hidden_output[0][:, None])\n",
    "\n",
    "hidden_error_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5],\n",
       "       [-0.2],\n",
       "       [ 0.1]])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00318364,  0.00105361],\n",
       "       [ 0.00127346, -0.00042144],\n",
       "       [-0.00063673,  0.00021072]])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_weights_i_h += x[0][:, None] * hidden_error_term.reshape(1,2)\n",
    "\n",
    "delta_weights_i_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01025281],\n",
       "       [-0.00963049]])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_weights_h_o += hidden_outputs[:, None] * output_error_term\n",
    "\n",
    "delta_weights_h_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_hidden_output -= learnrate * delta_weights_h_o / 1\n",
    "weights_input_hidden -= learnrate * delta_weights_i_h / 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.3034176 ],\n",
       "        [-0.09678984]]), array([[ 0.10106121, -0.2003512 ],\n",
       "        [ 0.39957551,  0.50014048],\n",
       "        [-0.29978776,  0.19992976]]))"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_hidden_output, weights_input_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "312px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
